#' MAXQDA.
#' 
#' Class to manage and get annotations from a MAXQDA file that stores annotations
#' to html documents that have previously been generated by polmineR. These html
#' documents are required to have character offset positions in tags.
#' 
#' @export MAXQDA
#' @importFrom R6 R6Class
#' @importFrom xml2 read_html xml_find_all xml_attrs
#' @importFrom data.table data.table as.data.table setkeyv setorderv
#' @importFrom DBI dbConnect dbGetQuery dbDisconnect
#' @importFrom RSQLite SQLite
#' @importFrom tools file_path_sans_ext
#' @importFrom polmineR get_token_stream encoding as.nativeEnc
#' @rdname MAXQDA
#' @examples
#' maxfile <- system.file(package = "maxqda", "extdata", "maxqda", "reuters.mx12")
#' htmlDir <- system.file(package = "maxqda", "extdata", "html", "reuters")
#' M <- MAXQDA$new(dbFilename = maxfile, htmlDir = htmlDir)
#' annotationsDT <- M$getAll()
MAXQDA <- R6Class(
  
  "MAXQDA",

  public = list(
    
    #' @field dbFilename the MAXQDA file (*.mx12) from which annotations are to
    #'   be extracted (full path)
    dbFilename = NULL, # "character",
    
    #' @field codings table with codings/annotations derived from the MAXQDA
    #'   file, a \code{data.table}
    codings = NULL, # a data.table
    
    #' @field codewords table with codewords derived from the MAXQDA file, a
    #'   \code{data.table}
    codewords = NULL, # data.table
    
    #' @field texts table with texts derived from the MAXQDA file, a
    #'   \code{data.table}
    texts = NULL,
    
    #' @field htmlDir directory where the html files that have been imported
    #'   into MAXQDA reside
    htmlDir = NULL,
    
    #' @description
    #' Create a new instance of class \code{MAXQDA}; the param \code{dbFilename}
    #' indicates the MAXQDA database, the \code{htmlDir} the directory where
    #' html files as generated with \code{polmineR} reside
    #' @param dbFilename filename of the MAXQDA database (file ending: ".mx12")
    #' @param htmlDir html directory
    initialize = function(dbFilename, htmlDir){
      self$htmlDir <- htmlDir
      self$dbFilename <- dbFilename
      self$getMaxqdaData()
    },
    
    #' @description 
    #' Fill the fields \code{codings}, \code{codewords}, and \code{texts} with
    #' \code{data.table} by extracting the respective tables from the MAXQDA
    #' file specified by field \code{dbFilename}
    getMaxqdaData = function(){
      dbconn <- dbConnect(SQLite(), self$dbFilename)
      self$codings <- as.data.table(dbGetQuery(dbconn, 'SELECT * FROM Codings'))
      self$codewords <- as.data.table(dbGetQuery(dbconn, 'SELECT * FROM Codewords'))
      setkeyv(self$codewords, cols = "ID")
      # In the column "Name" of the texts table, we find the filename of the 
      # html document that has been imported, stripped by the file ending (.html)
      self$texts <- as.data.table(dbGetQuery(dbconn, 'SELECT * FROM Texts'))
      # ID in texts > TextID in codings
      dbDisconnect(dbconn)
    },
    
    #' @description 
    #' Extract \code{data.table} with character offset positions and corpus
    #' positions from the html file specified by param \code{filename}
    #' @param filename filename of a html file that has been imported into MAXQDA
    getOffsetDT = function(filename){
      xmlDoc <- read_html(filename)
      nodes <- xml_find_all(xmlDoc, xpath = "//span")
      attrValues <- lapply(nodes, function(x) xml_attrs(x))
      dt <- data.table(do.call(rbind, attrValues))
      for (x in c("id", "left", "right")) dt[, eval(x) := as.integer(dt[[x]]), with = TRUE]
      dt
    },
    
    #' @description 
    #' Extract annotations for one document; essentially a worker called by the
    #' method \code{getAll}
    #' @param corpus corpus from which the partition is derived
    #' @param textId DONTKNOW
    #' @param offsetDT DONTKNOW
    getOne = function(textId, offsetDT, corpus = "REUTERS"){
      
      .getCpos <- function(.SD){
        offsetDT[["left_diff"]] <- offsetDT[["left"]] - .SD[["SegPos1X"]]
        offsetDT[["right_diff"]] <- offsetDT[["right"]] - .SD[["SegPos2X"]]
        ids <- offsetDT[left_diff >= 0][right_diff <= 0][["id"]]
        txt <- paste(
          get_token_stream(corpus, left = ids[1], right = ids[length(ids)], p_attribute = "word"),
          collapse = " "
        )
        data.table(
          left = ids[1], right = ids[length(ids)],
          txt = as.nativeEnc(txt, from = encoding(corpus)),
          codeID = .SD[["WordID"]]
          )
      }
      
      docCodings <- self$codings[TextID == textId]
      retval <- docCodings[, .getCpos(.SD), by = seq_len(nrow(docCodings))]
      setkeyv(retval, cols = "codeID")
      retval[["code"]] <- self$codewords[retval][["Name"]]
      retval[, "codeID" := NULL, with = TRUE][, "seq_len" := NULL, with = TRUE]
      setorderv(retval, cols = "left")
      setcolorder(retval, neworder = c("left", "right", "code", "txt"))
      retval
    },
    
    #' @description 
    #' Extract annotations for all documents that reside in the \code{htmlDir}
    #' that has been specified upon initialization
    #' @param verbose logical, whether to be talkative
    getAll = function(verbose = TRUE){
      dts <- lapply(
        Sys.glob(file.path(self$htmlDir, "*.html")),
        function(file){
          corpus <- "REUTERS"
          offsetDT <- self$getOffsetDT(file)
          docName <- tools::file_path_sans_ext(basename(file))
          if (verbose) message("... processing: ", docName)
          textId <- self$texts[Name == docName][["ID"]]
          DT <- self$getOne(textId = textId, offsetDT = offsetDT, corpus = corpus)
          DT[["document"]] <- docName
          DT
        }
      )
      rbindlist(dts)
    }
  )
)
